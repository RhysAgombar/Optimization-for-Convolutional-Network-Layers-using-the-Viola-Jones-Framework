@INPROCEEDINGS{viola,
  author={P. {Viola} and M. {Jones}},
  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
  title={Rapid object detection using a boosted cascade of simple features}, 
  year={2001},
  volume={1},
  number={},
  pages={I-I}}

@INPROCEEDINGS{viola_updated,
  author={P. {Viola} and M. {Jones}},
  booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001}, 
  title={Robust real-time face detection}, 
  year={2001},
  volume={2},
  number={},
  pages={747-747}}

@article{adaboost,
title = "A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting",
journal = "Journal of Computer and System Sciences",
volume = "55",
number = "1",
pages = "119 - 139",
year = "1997",
issn = "0022-0000",
doi = "https://doi.org/10.1006/jcss.1997.1504",
url = "http://www.sciencedirect.com/science/article/pii/S002200009791504X",
author = "Yoav Freund and Robert E Schapire",
abstract = "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone–Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
}

@book{dl_book,
title={Deep Learning},
author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
publisher={MIT Press},
note={\url{http://www.deeplearningbook.org}},
year={2016}
}

@book{nn_book,
author = {Gurney, Kevin},
title = {An  Introduction to Neural Networks},
year = {1997},
isbn = {1857286731},
publisher = {Taylor \& Francis, Inc.},
address = {USA}
}

@InProceedings{Rotated_Haar,
author="Du, Shaoyi
and Zheng, Nanning
and You, Qubo
and Wu, Yang
and Yuan, Maojun
and Wu, Jingjun",
editor="Zha, Hongbin
and Pan, Zhigeng
and Thwaites, Hal
and Addison, Alonzo C.
and Forte, Maurizio",
title="Rotated Haar-Like Features for Face Detection with In-Plane Rotation",
booktitle="Interactive Technologies and Sociotechnical Systems",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="128--137",
abstract="This paper extends the upright face detection framework proposed by Viola et al. 2001 to handle in-plane rotated faces. These haar-like features work inefficiently on rotated faces, so this paper proposes a new set of {\textpm}26.565 {\textdegree} haar-like features which can be calculated quickly to represent the features of rotated faces. Unlike previous face detection techniques in training quantities of samples to build different rotated detectors, with these new features, we address to build different rotated detectors by rotating an upright face detector directly so as to achieve in-plane rotated face detection. This approach is selected because of its computational efficiency, simplicity and training time saving. This proposed method is tested on CMU-MIT rotated test data and yields good results in accuracy and maintains speed advantage.",
isbn="978-3-540-46305-4"
}

@inproceedings{ds:Casablanca_Dataset,
	author = {Vu, Tuan{-}Hung and Osokin, Anton and Laptev, Ivan},
	title = {Context-aware {CNNs} for person head detection},
	booktitle =  {International Conference on Computer Vision (ICCV)},
	year = {2015}}

@TechReport{ds:FDDB_Dataset,
  author = {Vidit Jain and Erik Learned-Miller},
  title =  {FDDB: A Benchmark for Face Detection in Unconstrained Settings},
  institution =  {University of Massachusetts, Amherst},
  year = {2010},
  number = {UM-CS-2010-009}
  }


@inproceedings{alex,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}


@INPROCEEDINGS{VJ_CRF,

  author={ {Xiaofeng Ren}},

  booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition}, 

  title={Finding people in archive films through tracking}, 

  year={2008},

  volume={},

  number={},

  pages={1-8}}

@INPROCEEDINGS{HeadHunter,

  author={J. {Yan} and X. {Zhang} and Z. {Lei} and S. Z. {Li}},

  booktitle={2013 International Conference on Biometrics (ICB)}, 

  title={Real-time high performance deformable model for face detection in the wild}, 

  year={2013},

  volume={},

  number={},

  pages={1-6}}


@ARTICLE{DPM,

  author={P. F. {Felzenszwalb} and R. B. {Girshick} and D. {McAllester} and D. {Ramanan}},

  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 

  title={Object Detection with Discriminatively Trained Part-Based Models}, 

  year={2010},

  volume={32},

  number={9},

  pages={1627-1645}}


@InProceedings{SDD,
author="Liu, Wei
and Anguelov, Dragomir
and Erhan, Dumitru
and Szegedy, Christian
and Reed, Scott
and Fu, Cheng-Yang
and Berg, Alexander C.",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="SSD: Single Shot MultiBox Detector",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="21--37",
abstract="We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For {\$}{\$}300 {\backslash}times 300{\$}{\$}300{\texttimes}300input, SSD achieves 74.3 {\%} mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for {\$}{\$}512 {\backslash}times 512{\$}{\$}512{\texttimes}512input, SSD achieves 76.9 {\%} mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.",
isbn="978-3-319-46448-0"
}


@ARTICLE{FRCNN,

  author={S. {Ren} and K. {He} and R. {Girshick} and J. {Sun}},

  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 

  title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 

  year={2017},

  volume={39},

  number={6},

  pages={1137-1149}}


@inproceedings{RFCN,
  title={R-fcn: Object detection via region-based fully convolutional networks},
  author={Dai, Jifeng and Li, Yi and He, Kaiming and Sun, Jian},
  booktitle={Advances in neural information processing systems},
  pages={379--387},
  year={2016}
}

@INPROCEEDINGS{YOLO9000,

  author={J. {Redmon} and A. {Farhadi}},

  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={YOLO9000: Better, Faster, Stronger}, 

  year={2017},

  volume={},

  number={},

  pages={6517-6525}}



@INPROCEEDINGS{LRCNN,

  author={T. {Vu} and A. {Osokin} and I. {Laptev}},

  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 

  title={Context-Aware CNNs for Person Head Detection}, 

  year={2015},

  volume={},

  number={},

  pages={2893-2901}}

@INPROCEEDINGS{Face_detection_Comparison,
  author={L. T. {Nguyen-Meidine} and E. {Granger} and M. {Kiran} and L. {Blais-Morin}},
  booktitle={2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)}, 
  title={A comparison of CNN-based face and head detectors for real-time video surveillance applications}, 
  year={2017},
  volume={},
  number={},
  pages={1-7}}

@inproceedings{DL_vs_TCV,
  title={Deep learning vs. traditional computer vision},
  author={O’Mahony, Niall and Campbell, Sean and Carvalho, Anderson and Harapanahalli, Suman and Hernandez, Gustavo Velasco and Krpalkova, Lenka and Riordan, Daniel and Walsh, Joseph},
  booktitle={Science and Information Conference},
  pages={128--144},
  year={2019},
  organization={Springer}
}

@phdthesis{neuron_image,
author = {Ioannou, Yani},
school = {University of Cambridge},
year = {2017},
month = {09},
title = {Structural Priors in Deep Neural Networks},
doi = {10.17863/CAM.26357}
}

 @misc{activation_functions, 
 title={Complete Guide of Activation Functions}, howpublished = {\url{https://towardsdatascience.com/complete-guide-of-activation-functions-34076e95d044}}, 
 author={Jain, Pawan}, 
 year={2020},
 month={May}
 }
 
 @article{searching_for_activation_functions,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@article{backprop,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}

@article{vgg16,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{lenet5,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}


 @misc{max_pool_graphic, 
 title={CS231n Convolutional Neural Networks for Visual Recognition}, howpublished={\url{https://cs231n.github.io/convolutional-networks/}},
 year={2020}
 }

@misc{VGG16_graphic, 
howpublished = {\url{https://neurohive.io/en/popular-networks/vgg16/}}, 
journal={VGG16 - Convolutional Network for Classification and Detection}, 
author={Hassan, Muneeb ul}, 
year={2018}, 
month={Nov}
}

@article{lenet_postal_service,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{ternary,
  title={Ternary weight networks},
  author={Li, Fengfu and Zhang, Bo and Liu, Bin},
  journal={arXiv preprint arXiv:1605.04711},
  year={2016}
}

@article{VGG16_challenge,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@InProceedings{binary,
author="Rastegari, Mohammad
and Ordonez, Vicente
and Redmon, Joseph
and Farhadi, Ali",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="525--542",
abstract="We propose two efficient approximations to standard convolutional neural networks: Binary-Weight-Networks and XNOR-Networks. In Binary-Weight-Networks, the filters are approximated with binary values resulting in 32{\$}{\$}{\backslash}times {\$}{\$}{\texttimes}memory saving. In XNOR-Networks, both the filters and the input to convolutional layers are binary. XNOR-Networks approximate convolutions using primarily binary operations. This results in 58{\$}{\$}{\backslash}times {\$}{\$}{\texttimes}faster convolutional operations (in terms of number of the high precision operations) and 32{\$}{\$}{\backslash}times {\$}{\$}{\texttimes}memory savings. XNOR-Nets offer the possibility of running state-of-the-art networks on CPUs (rather than GPUs) in real-time. Our binary networks are simple, accurate, efficient, and work on challenging visual tasks. We evaluate our approach on the ImageNet classification task. The classification accuracy with a Binary-Weight-Network version of AlexNet is the same as the full-precision AlexNet. We compare our method with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than {\$}{\$}16{\backslash},{\backslash}{\%}{\$}{\$}16{\%}in top-1 accuracy. Our code is available at: http://allenai.org/plato/xnornet.",
isbn="978-3-319-46493-0"
}

@article{mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume={2},
  year={2010}
}

@article{cifar,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}


@INPROCEEDINGS{imagenet,

  author={J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and  {Kai Li} and  {Li Fei-Fei}},

  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 

  title={ImageNet: A large-scale hierarchical image database}, 

  year={2009},

  volume={},

  number={},

  pages={248-255}
  }

@misc{batch_norm,
    title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
    author={Sergey Ioffe and Christian Szegedy},
    year={2015},
    eprint={1502.03167},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{ds_analysis,
author = {Lim, Seung-Hwan and Young, Steven and Patton, Robert},
year = {2016},
month = {04},
pages = {},
title = {An analysis of image storage systems for scalable training of deep neural networks}
}

@misc{cifar-image, 
url={https://www.cs.toronto.edu/~kriz/cifar.html}, 
howpublished = {\url{https://www.cs.toronto.edu/~kriz/cifar.html}}, 
journal={CIFAR-10 and CIFAR-100 datasets}, 
author={Krizhevsky, Alex}} 

@misc{yolo,
    title={You Only Look Once: Unified, Real-Time Object Detection},
    author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
    year={2015},
    eprint={1506.02640},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{stat,
author = { D.   Lu  and  Q.   Weng },
title = {A survey of image classification methods and techniques for improving classification performance},
journal = {International Journal of Remote Sensing},
volume = {28},
number = {5},
pages = {823-870},
year  = {2007},
publisher = {Taylor \& Francis},
doi = {10.1080/01431160600746456},
URL = { 
        https://doi.org/10.1080/01431160600746456
},
eprint = { 
        https://doi.org/10.1080/01431160600746456
}
}

@misc{opencv, 
title={Template Matching}, 
howpublished = {\url{https://docs.opencv.org/master/d4/dc6/tutorial_py_template_matching.html}}, journal={OpenCV}
} 

@misc{adam,
    title={Adam: A Method for Stochastic Optimization},
    author={Diederik P. Kingma and Jimmy Ba},
    year={2014},
    eprint={1412.6980},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@incollection{Versatile,
title = {Learning Versatile Filters for Efficient Convolutional Neural Networks},
author = {Wang, Yunhe and Xu, Chang and XU, Chunjing and Xu, Chao and Tao, Dacheng},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {1608--1618},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks.pdf}
}

@INPROCEEDINGS{Depthwise,

  author={D. {Haase} and M. {Amthor}},

  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Rethinking Depthwise Separable Convolutions: How Intra-Kernel Correlations Lead to Improved MobileNets}, 

  year={2020},

  volume={},

  number={},

  pages={14588-14597}
  }

@INPROCEEDINGS{PruningC,

  author={Y. {He} and Y. {Ding} and P. {Liu} and L. {Zhu} and H. {Zhang} and Y. {Yang}},

  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Learning Filter Pruning Criteria for Deep Convolutional Neural Networks Acceleration}, 

  year={2020},

  volume={},

  number={},

  pages={2006-2015}
  }
  
  
@misc{HRank,
    title={HRank: Filter Pruning using High-Rank Feature Map},
    author={Mingbao Lin and Rongrong Ji and Yan Wang and Yichen Zhang and Baochang Zhang and Yonghong Tian and Ling Shao},
    year={2020},
    eprint={2002.10179},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@INPROCEEDINGS{PruningG,

  author={Y. {He} and P. {Liu} and Z. {Wang} and Z. {Hu} and Y. {Yang}},

  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration}, 

  year={2019},

  volume={},

  number={},

  pages={4335-4344}}

@inproceedings{
DCPruning,
title={Dynamic Channel Pruning: Feature Boosting and Suppression},
author={Xitong Gao and Yiren Zhao and Łukasz Dudziak and Robert Mullins and Cheng-zhong Xu},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJxh2j0qYm},
}

@INPROCEEDINGS{NLDeep,

  author={Z. {Luo} and A. {Mishra} and A. {Achkar} and J. {Eichel} and S. {Li} and P. {Jodoin}},

  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Non-local Deep Features for Salient Object Detection}, 

  year={2017},

  volume={},

  number={},

  pages={6593-6601}}

@misc{Reparam,
    title={Learning Discrete Weights Using the Local Reparameterization Trick},
    author={Oran Shayer and Dan Levi and Ethan Fetaya},
    year={2017},
    eprint={1710.07739},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{LRE,
  author    = {Max Jaderberg and
               Andrea Vedaldi and
               Andrew Zisserman},
  title     = {Speeding up Convolutional Neural Networks with Low Rank Expansions},
  journal   = {CoRR},
  volume    = {abs/1405.3866},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.3866},
  archivePrefix = {arXiv},
  eprint    = {1405.3866},
  timestamp = {Mon, 13 Aug 2018 16:47:55 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JaderbergVZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{FLMA,
  title={Compression of deep convolutional neural networks for fast and low power mobile applications},
  author={Kim, Yong-Deok and Park, Eunhyeok and Yoo, Sungjoo and Choi, Taelim and Yang, Lu and Shin, Dongjun},
  journal={arXiv preprint arXiv:1511.06530},
  year={2015}
}

@incollection{GateD,
title = {Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks},
author = {You, Zhonghui and Yan, Kun and Ye, Jinmian and Ma, Meng and Wang, Ping},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {2133--2144},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8486-gate-decorator-global-filter-pruning-method-for-accelerating-deep-convolutional-neural-networks.pdf}
}

@incollection{FJPEG,
title = {Faster Neural Networks Straight from JPEG},
author = {Gueguen, Lionel and Sergeev, Alex and Kadlec, Ben and Liu, Rosanne and Yosinski, Jason},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {3933--3944},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7649-faster-neural-networks-straight-from-jpeg.pdf}
}

@inproceedings{ChannelNet,
  title={Channelnets: Compact and efficient convolutional neural networks via channel-wise convolutions},
  author={Gao, Hongyang and Wang, Zhengyang and Ji, Shuiwang},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5197--5205},
  year={2018}
}

@incollection{LWC,
title = {Learning both Weights and Connections for Efficient Neural Network},
author = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {1135--1143},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5784-learning-both-weights-and-connections-for-efficient-neural-network.pdf}
}

@misc{DynaConv,
    title={Dynamic Convolutions: Exploiting Spatial Sparsity for Faster Inference},
    author={Thomas Verelst and Tinne Tuytelaars},
    year={2019},
    eprint={1912.03203},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{
Winograd,
title={Efficient Sparse-Winograd Convolutional Neural Networks},
author={Xingyu Liu and Jeff Pool and Song Han and William J. Dally},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=HJzgZ3JCW},
}

@incollection{BoxConv,
title = {Deep Neural Networks with Box Convolutions},
author = {Burkov, Egor and Lempitsky, Victor},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {6211--6221},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7859-deep-neural-networks-with-box-convolutions.pdf}
}

@incollection{PerfCNN,
title = {PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions},
author = {Figurnov, Mikhail and Ibraimova, Aizhan and Vetrov, Dmitry P and Kohli, Pushmeet},
booktitle = {Advances in Neural Information Processing Systems 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {947--955},
year = {2016},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6463-perforatedcnns-acceleration-through-elimination-of-redundant-convolutions.pdf}
}

@misc{ECA,
    title={ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks},
    author={Qilong Wang and Banggu Wu and Pengfei Zhu and Peihua Li and Wangmeng Zuo and Qinghua Hu},
    year={2019},
    eprint={1910.03151},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{Sacc,
    title={SaccadeNet: A Fast and Accurate Object Detector},
    author={Shiyi Lan and Zhou Ren and Yi Wu and Larry S. Davis and Gang Hua},
    year={2020},
    eprint={2003.12125},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{FSConv,
    title={Fast Sparse ConvNets},
    author={Erich Elsen and Marat Dukhan and Trevor Gale and Karen Simonyan},
    year={2019},
    eprint={1911.09723},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{AccConv,
    title={Accelerating Convolutional Neural Networks via Activation Map Compression},
    author={Georgios Georgiadis},
    year={2018},
    eprint={1812.04056},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@INPROCEEDINGS{Shuffle,

  author={X. {Zhang} and X. {Zhou} and M. {Lin} and J. {Sun}},

  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 

  title={ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices}, 

  year={2018},

  volume={},

  number={},

  pages={6848-6856}}

@INPROCEEDINGS{DCConv,

  author={G. {Huang} and Z. {Liu} and L. {Van Der Maaten} and K. Q. {Weinberger}},

  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Densely Connected Convolutional Networks}, 

  year={2017},

  volume={},

  number={},

  pages={2261-2269}}

@article{LCNN,
  author    = {Hessam Bagherinezhad and
               Mohammad Rastegari and
               Ali Farhadi},
  title     = {{LCNN:} Lookup-based Convolutional Neural Network},
  journal   = {CoRR},
  volume    = {abs/1611.06473},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.06473},
  archivePrefix = {arXiv},
  eprint    = {1611.06473},
  timestamp = {Mon, 13 Aug 2018 16:46:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BagherinezhadRF16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
BLN,
title={Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition},
author={Chun-Fu (Richard) Chen and Quanfu Fan and Neil Mallinar and Tom Sercu and Rogerio Feris},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HJMHpjC9Ym},
}

@misc{f_RCNN,
    title={Fast R-CNN},
    author={Ross Girshick},
    year={2015},
    eprint={1504.08083},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{mit_cv,
  title={The summer vision project},
  author={Papert, Seymour A},
  year={1966}
}

@article{fix,
  title={Fixing the train-test resolution discrepancy: FixEfficientNet},
  author={Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2003.08237},
  year={2020}
}